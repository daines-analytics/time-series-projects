{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Model for Monthly Shampoo Sales Using Python and ETS\n",
    "### David Lowe\n",
    "### April 29, 2020\n",
    "\n",
    "Template Credit: Adapted from a template made available by Dr. Jason Brownlee of Machine Learning Mastery. https://machinelearningmastery.com/\n",
    "\n",
    "SUMMARY: The purpose of this project is to construct a time series prediction model and document the end-to-end steps using a template. The Monthly Shampoo Sales dataset is a time series situation where we are trying to forecast future outcomes based on past data points.\n",
    "\n",
    "Additional Notes: This is a replication, with some small modifications, of Dr. Jason Brownlee's blog post, How to Grid Search Triple Exponential Smoothing for Time Series Forecasting in Python (https://machinelearningmastery.com/how-to-grid-search-triple-exponential-smoothing-for-time-series-forecasting-in-python/). I plan to leverage Dr. Brownlee's exponential smoothing or ETS (Error, Trend and Seasonality) tutorial examples and build an ETS-based notebook template for future uses.\n",
    "\n",
    "INTRODUCTION: The problem is to forecast the monthly number of shampoo sales. The dataset described a time-series of monthly shampoo sales for three years, and there are 36 observations. We will use the first 24 observations for training the model while using the remaining 12 observations for testing the model.\n",
    "\n",
    "ANALYSIS: The ETS model, which models multiplicative trend with no trend dampening, no BoxCox transform, and no bias removal, appeared to have the lowest RMSE at 83.72.\n",
    "\n",
    "CONCLUSION: For this dataset, the chosen ETS model achieved a satisfactory result and should be considered for further modeling.\n",
    "\n",
    "Dataset Used: Sales of shampoo over a three year period\n",
    "\n",
    "Dataset ML Model: Time series forecast with numerical attributes\n",
    "\n",
    "Dataset Reference: Rob Hyndman and Yangzhuoran Yang (2018). tsdl: Time Series Data Library. v0.1.0. https://pkg.yangzhuoranyang./tsdl/.\n",
    "\n",
    "A time series predictive modeling project genrally can be broken down into about five major tasks:\n",
    "\n",
    "1. Set up Environment\n",
    "2. Inspect and Explore Data\n",
    "3. Clean and Pre-Process Data\n",
    "4. Fit and Evaluate Models\n",
    "5. Finalize Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Prepare Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a) Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random seed number for reproducible results\n",
    "seedNum = 888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import smtplib\n",
    "import pmdarima as pm\n",
    "import pandas_datareader.data as web\n",
    "from datetime import datetime\n",
    "from email.message import EmailMessage\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b) Set up the controlling parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin the timer for the script processing\n",
    "startTimeScript = datetime.now()\n",
    "\n",
    "# Set up the verbose flag to print detailed messages for debugging (setting True will activate!)\n",
    "verbose = False\n",
    "\n",
    "# Set up the flag to stop sending progress emails (setting to True will send status emails!)\n",
    "notifyStatus = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the email notification function\n",
    "def email_notify(msg_text):\n",
    "    sender = os.environ.get('MAIL_SENDER')\n",
    "    receiver = os.environ.get('MAIL_RECEIVER')\n",
    "    gateway = os.environ.get('SMTP_GATEWAY')\n",
    "    smtpuser = os.environ.get('SMTP_USERNAME')\n",
    "    password = os.environ.get('SMTP_PASSWORD')\n",
    "    if sender==None or receiver==None or gateway==None or smtpuser==None or password==None:\n",
    "        sys.exit(\"Incomplete email setup info. Script Processing Aborted!!!\")\n",
    "    msg = EmailMessage()\n",
    "    msg.set_content(msg_text)\n",
    "    msg['Subject'] = 'Notification from Python ARIMA Time Series Script'\n",
    "    msg['From'] = sender\n",
    "    msg['To'] = receiver\n",
    "    server = smtplib.SMTP(gateway, 587)\n",
    "    server.starttls()\n",
    "    server.login(smtpuser, password)\n",
    "    server.send_message(msg)\n",
    "    server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 1. Prepare Environment has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c) Acquire and Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "time_series = pd.read_csv('https://dainesanalytics.com/datasets/time-series-data-library/tsdl469.csv', index_col='idx', parse_dates=True)\n",
    "data = time_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the train/test split ratio\n",
    "n_test = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 36 entries, 2001-01-01 to 2001-03-12\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   values  36 non-null     float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 576.0 bytes\n"
     ]
    }
   ],
   "source": [
    "time_series.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>145.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>183.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>119.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>180.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            values\n",
       "idx               \n",
       "2001-01-01   266.0\n",
       "2001-01-02   145.9\n",
       "2001-01-03   183.1\n",
       "2001-01-04   119.3\n",
       "2001-01-05   180.3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-03-08</th>\n",
       "      <td>407.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-09</th>\n",
       "      <td>682.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-10</th>\n",
       "      <td>475.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-11</th>\n",
       "      <td>581.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-12</th>\n",
       "      <td>646.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            values\n",
       "idx               \n",
       "2001-03-08   407.6\n",
       "2001-03-09   682.0\n",
       "2001-03-10   475.3\n",
       "2001-03-11   581.3\n",
       "2001-03-12   646.9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section will be further developed in future iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 1. Prepare Environment completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Inspect and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 2. Inspect and Explore Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section will be further developed in future iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 2. Inspect and Explore Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Clean and Pre-Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 3. Clean and Pre-Process Data has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section will be further developed in future iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 3. Clean and Pre-Process Data completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Fit and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 4. Fit and Evaluate Models has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\thistory = np.array(history)\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn math.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitting has begun!\n",
      " > Model[['add', False, None, None, False, True]] 106.431\n",
      " > Model[['add', False, None, None, True, True]] 110.230\n",
      " > Model[['add', False, None, None, False, False]] 104.874\n",
      " > Model[['add', False, None, None, True, False]] 108.665\n",
      " > Model[['mul', False, None, None, True, True]] 110.576\n",
      " > Model[['mul', False, None, None, True, False]] 108.747\n",
      " > Model[['mul', False, None, None, False, True]] 86.324\n",
      " > Model[['add', True, None, None, False, True]] 97.919\n",
      " > Model[['add', True, None, None, True, True]] 97.094\n",
      " > Model[['mul', False, None, None, False, False]] 83.725\n",
      " > Model[[None, False, None, None, True, True]] 96.683\n",
      " > Model[[None, False, None, None, True, False]] 112.384\n",
      " > Model[[None, False, None, None, False, True]] 99.415\n",
      " > Model[[None, False, None, None, False, False]] 108.031\n",
      " > Model[['mul', True, None, None, True, True]] 1561.970\n",
      " > Model[['add', True, None, None, False, False]] 103.069\n",
      " > Model[['add', True, None, None, True, False]] 106.559\n",
      " > Model[['mul', True, None, None, True, False]] 106.167\n",
      " > Model[['mul', True, None, None, False, True]] 102.446\n",
      " > Model[['mul', True, None, None, False, False]] 102.152\n",
      "Model fitting completed!\n"
     ]
    }
   ],
   "source": [
    "# model configs\n",
    "cfg_list = exp_smoothing_configs()\n",
    "# grid search\n",
    "print('Model fitting has begun!')\n",
    "scores = grid_search(data[:,0], cfg_list, n_test)\n",
    "print('Model fitting completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 4. Fit and Evaluate Models completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Finalize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 5. Finalize Model has begun! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing the top three models:\n",
      "['mul', False, None, None, False, False] 83.7245585999172\n",
      "['mul', False, None, None, False, True] 86.32425287302618\n",
      "[None, False, None, None, True, True] 96.68252034213745\n"
     ]
    }
   ],
   "source": [
    "# list top 3 configs\n",
    "print('Listing the top three models:')\n",
    "for cfg, error in scores[:3]:\n",
    "\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (notifyStatus): email_notify(\"Task 5. Finalize Model completed! \"+datetime.now().strftime('%a %B %d, %Y %I:%M:%S %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time for the script: 0:00:16.045495\n"
     ]
    }
   ],
   "source": [
    "print ('Total time for the script:',(datetime.now() - startTimeScript))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
